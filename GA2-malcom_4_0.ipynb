{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Assignment 2 - Air Quality and Weather in the Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to This Template Notebook\n",
    "\n",
    "* This is a **group** notebook.\n",
    "* Make sure you work in a **copy** of `...-template.ipynb`,\n",
    "**renamed** to `...-yourIDnrs.ipynb`,\n",
    "where `yourIDnrs` is the TU/e identification numbers of the members of the group.\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"danger\">\n",
    "<h3>Integrity</h3>\n",
    "<ul>\n",
    "    <li>In this course you must act according to the rules of the TU/e code of scientific conduct.</li>\n",
    "    <li>This exercise or graded assignment is to be executed by the members of the group independently from other people.</li>\n",
    "    <li>You must not copy from the Internet, your friends, books... If you represent other people's work as your own, then that constitutes fraud and will be reported to the Examination Committee.</li>\n",
    "    <li>Making your work available to others (complicity) also constitutes fraud.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "You are expected to work with Python code and Markdown in this notebook.\n",
    "\n",
    "Proceed in this notebook as follows:\n",
    "* **Read** the assignment (separate PDF).\n",
    "* **Write** your decisions/solutions/interpretations in the appropriate sections.\n",
    "  * For this you can use both Code and Markdown cells. Information about how to use these cells is available in the _Getting Started_ assignment.\n",
    "* **Run** _all_ code cells (also the ones _without_ your code),\n",
    "    _in linear order_ from the first code cell.\n",
    "\n",
    "**Personalize your notebook**:\n",
    "1. Copy the following line of code:\n",
    "\n",
    "  ```python\n",
    "  AUTHOR_ID_NRS = ['1234567', '2234567', '3234567', '4234567']\n",
    "  ```\n",
    "1. Paste them between the marker lines in the next code cell.\n",
    "1. Fill in the _identification numbers_ of all members of the group as a list of strings between the `Author` markers.\n",
    "1. Run the code cell by putting the cursor there and typing **Control-Enter**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Author] Name, Id.nr., Date, as strings (1 point)\n",
    "\n",
    "AUTHOR_ID_NRS = ['2027453', '1989596', '2007630', '2056313']\n",
    "\n",
    "#// END_TODO [Author]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Preparation](#Preparation)\n",
    "    - [Load the libraries](#Load-the-libraries)\n",
    "- [Part 1a. Hypothesis selection](#Part-1a:-Hypothesis-selection)\n",
    "- [Part 1b. Hypothesis refinement](#Part-1b:-Hypothesis-refinement)\n",
    "- [Part 2. Queries and data cleaning](#Part-2:-Queries-and-data-cleaning)\n",
    "- [Part 3. Hypothesis testing and interpretation](#Part-3.-Hypothesis-testing-and-interpretation)\n",
    "- [Part 4. Pitching results](#Part-4.-Pitching-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression         # for linear regression\n",
    "from sklearn.cluster import KMeans                        # for clustering\n",
    "from sklearn.tree import DecisionTreeClassifier           # for decision tree mining\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from treeviz import tree_print                            # to print decision tree (gives an error for now)\n",
    "\n",
    "import scipy.stats as stats                               # to compute z-scores\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import sqlite3                                            # to interact with the database\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "%matplotlib inline                                 \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns                                     # also improves the look of plots\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = 10, 5                    # default hor./vert. size of plots, in inches\n",
    "plt.rcParams['lines.markeredgewidth'] = 1                 # to fix issue with seaborn box plots; needed after import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1a: Hypothesis selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our research question is as follows: What is the influence of the seasons on the air quality?\n",
    "For this question we have made the following hypothesis:\n",
    "    1. The concenctration of NOx is directly proportional to the wind speed.\n",
    "    2.The effect on PM10 and pm2.5. A higher wind speed decreases the concentration of these particles.\n",
    "    3. The concentration of NO decreases with the increase of temperature  \n",
    "\n",
    "For each of these hypothesis we have a reason why we think it is worth to investigate the topic. They are as follows:\n",
    "    1. NOx or nitrogen oxides can react to form smog or acid rain, which both are bad for the local enviroment and to the health of humans.\n",
    "    2. PM particles, either PM_10 or PM_2.5 are so small they can damage the tissue in the lungs and cause lung inflammation.\n",
    "    3. Temperature can have an influence on the pollution of nitrogen monoxide as low temperatures can lead to a layer of warm air forming above the ground trapping cold air and pollutants (including nitrogen monoxide) close¬†to¬†the¬†ground.\n",
    "Al these reasons were interesting to us since they all effect the health and reduce the air quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1b: Hypothesis refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *concentration of NOx* decreases with *high wind speeds*.\n",
    "\n",
    "1.\n",
    "*concentration of NOx*\n",
    "    \n",
    "    what nitrogen oxides are included in the concentration of NOx( which ones will we measure)?\n",
    "\n",
    "    how will we measure NOx?\n",
    "        -what do we consider high/low?\n",
    "        -what time periods will we choose?\n",
    "    \n",
    "    should we measure the different oxides differently/separately?\n",
    "    \n",
    "*high wind speeds*\n",
    "   \n",
    "    what do we consider high wind speeds?\n",
    "\n",
    "    what do we consider low wind speeds?\n",
    "    \n",
    "    are there variations in wind speed we should consider?\n",
    "    \n",
    "    how will we treat extreme wind events?\n",
    "       \n",
    "    \n",
    "confunding variables\n",
    "   \n",
    "    what other factors might affect NOx concentration?\n",
    "        -temperature,humidity...?\n",
    "        -are there any local stations, traffic... that might increase these values?\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "2. \n",
    "*concentration of NOx*\n",
    "    The concentration of NOx is the dependent variable and refers to the concentration of Nitrogen Oxides (NOx) in ùúág/m^3\n",
    "    we will measure NO_2 and NO\n",
    "    These will be measured separately as they each might have a different effect on the air quality.\n",
    "    we will consider high concentrations anything over the 90th percentile, and low anything below the 10th percentile. \n",
    "    'normal'concentrations will be considered as those in the IQR.\n",
    "\n",
    "*high wind speeds*\n",
    "    Wind speed, on the other hand, is this project's independent variable and it is defined the following way.The mean wind \n",
    "    speed in metres per second (m/s) 10 minutes before each measurement is taken.\n",
    "        Wind speeds between 0 and 30 m/s are considered low wind speeds, while those between 30 and 60 m/s are considered medium \n",
    "        and those above 60 and 90 m/s are considered high wind speeds, extreme wind will be above 90m/s. \n",
    "  \n",
    "  \n",
    "        \n",
    "cofunding variables\n",
    "    Additionally, temperature is going to be considered as a confounding variable as it has a positive correlation with the \n",
    "    concentration of NOx.(_should we only measure above/below certain values? how do we mitigate this?_)\n",
    "    another thing that we must consider is the traffic and industries close to the stations as higer traffic causes more no2 to \n",
    "    be produced. therefore we will only look at street stations as more NOx is produced there.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.\n",
    "Finally, in order to conduct the assignment data collected from three stations, Maastricht, Groningen and Rotterdam is going to be used. Furthermore, data from three other stations surrounding each one of the previous stations is going to be used to avoid possible biases or mistakes that might have happened at a particular weather¬†station.(specify which stations, give names and reason behind) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4.\n",
    "‚Ä¢ what data (including in which format) you need\n",
    "\n",
    "    data of daily mean NOx concentrations data and daily mean wind speed will be used in order to compare how it changes each season. then we will go deeper and asses the daily windspeeds and NOx concentrations of one of the seasons/months in order to compare how they affect each other. This means data will be separated into type of station, season, month, and day.  \n",
    "\n",
    "‚Ä¢ where you will get this data from\n",
    "\n",
    "    data will be obtained from the following stations, the stations will be limited to street stationsas traffic levels \n",
    "    influence the amount of NOx produced.(specify which stations, give names) \n",
    "\n",
    "‚Ä¢ which technologies you intend to use\n",
    "    .......\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The original hypothesis was ‚ÄúThe concentration of NOx decreases with high wind speeds.‚Äù\n",
    "We have refined it as follows:\n",
    "    air quality\n",
    "        during 2021(or a certain amount of years, decide as group)- to make the population more homogenuos, eliminating cofunding variables such as covid year.\n",
    "\n",
    "        from urban areas with traffic and industrial activities- as we are only using data from street stations \n",
    "\n",
    "        considering different stations across the netherlands- as we only have data available from the netherlands\n",
    "\n",
    "        shows that the concentration of different nitrogen oxides (such as NO_2 and NO)- to specify what oxides we will be assesing\n",
    "        \n",
    "        decrease with high wind speeds.- to have a comparison with another variable\n",
    "\n",
    "\n",
    "\n",
    "therefore, the refined hypothesis becomes:\n",
    "\"air quality data during 2021 (*choose year with best results, and add extra info above*) from urban areas with traffic and industrial activities, considering different stations across the netherlands, shows that the concentration of different nitrogen oxides (such as NO_2 and NO) decrease with high¬†wind¬†speeds.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Queries and data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following all the coordinations of the datapoints will be mentioned for easy use.\n",
    "\n",
    " - Main point maastricht: lat: 50.906000, lon: 5.762000\n",
    " - Main point rotterdam: lat: 51.962000, lon 4.447000\n",
    " - Main point Schiphol: lat: 52.318000, lon: 4.790000\n",
    "\n",
    "Smaller points close to maastricht:\n",
    "- maastricht a2 nassaulaan: lat: 50.845941 lon  5.714745\n",
    "- maastricht hoge fronten: lat: 50.852049  lon: 5.675796\n",
    "- Maastricht-A2 Kasteel Hillenraadweg  50.859810   5.713810 \n",
    "\n",
    "Smaller points close to rotterdam:\n",
    "- Hoek van Holland-Berghaven  51.977628   4.121226\n",
    "-  Rotterdam Zuid-Zwartewaalstraat  51.893617   4.487528\n",
    "- Vlaardingen-Riouwlaan  51.914883   4.329430\n",
    "\n",
    "Smaller points close to Schiphol:\n",
    "- Hoofddorp-Hoofdweg  52.327464   4.715008\n",
    "- Haarlem-Schipholweg  52.370508   4.642319  \n",
    "- Badhoevedorp-Sloterweg  52.334003   4.774006\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first assign the coordinates to different variables\n",
    "lat_maastricht = '50.906000'\n",
    "lon_maastricht = '5.762000'\n",
    "\n",
    "lat_rotterdam = '51.962000'\n",
    "lon_rotterdam = '4.447000'\n",
    "\n",
    "lat_schiphol = '52.318000'\n",
    "lon_schiphol = '4.790000'\n",
    "# first point of maastricht is called m1 etc and rotterdam r1 etc and schiphol s1 etc\n",
    "\n",
    "lat_m1 = '50.845941'\n",
    "lon_m1 = '5.714745'\n",
    "\n",
    "lat_m2 = '50.852049'\n",
    "lon_m2 = '5.675796'\n",
    "\n",
    "lat_m3 = '50.859810'\n",
    "lon_m3 = '5.713810'\n",
    "\n",
    "lat_r1 = '51.977628'\n",
    "lon_r1 = '4.121226' \n",
    "\n",
    "lat_r2 = '51.893617' \n",
    "lon_r2 = '4.487528'\n",
    "\n",
    "lat_r3 = '51.914883'\n",
    "lon_r3 = '4.329430' \n",
    "\n",
    "lat_s1 = '52.327464'\n",
    "lon_s1 = '4.715008'\n",
    "\n",
    "lat_s2 = '52.370508'\n",
    "lon_s2 = '4.642319'\n",
    "\n",
    "lat_s3 = '52.334003'\n",
    "lon_s3 = '4.774006'\n",
    "\n",
    "compound= 'no_x' #this assigns the particle we want to investigate to the variable compound\n",
    "weather_factor = 'wind_speed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to connect to the correct database\n",
    "conn = sqlite3.connect('./datasets/aqw.db')\n",
    "# define the compound 1 etc\n",
    "compound1 = 'no_x'\n",
    "compound2 = 'pm_10'\n",
    "weather_factor= 'wind_speed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT *\nFROM weather_stations\nWHERE latitude = '50.906000'  AND longitude = '5.762000'\n\n': no such table: weather_stations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2018\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: weather_stations",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# now that all the coordinates are assigned to variables it will be easier to make the query's per point\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# let's start with the three main points\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#MSTRCHT = maastricht\u001b[39;00m\n\u001b[0;32m      4\u001b[0m QUERY_MSTRCHT1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mSELECT *\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mFROM weather_stations\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mWHERE latitude = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50.906000\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  AND longitude = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5.762000\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m df_mstrcht1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQUERY_MSTRCHT1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m df_mstrcht1\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:397\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03mparameter will be converted to UTC.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    396\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2078\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2067\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2068\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2075\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   2077\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 2078\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2079\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2030\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2029\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2030\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT *\nFROM weather_stations\nWHERE latitude = '50.906000'  AND longitude = '5.762000'\n\n': no such table: weather_stations"
     ]
    }
   ],
   "source": [
    "# now that all the coordinates are assigned to variables it will be easier to make the query's per point\n",
    "# let's start with the three main points\n",
    "#MSTRCHT = maastricht\n",
    "QUERY_MSTRCHT1 = \"\"\"\n",
    "SELECT *\n",
    "FROM weather_stations\n",
    "WHERE latitude = '50.906000'  AND longitude = '5.762000'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_mstrcht1 = pd.read_sql_query(QUERY_MSTRCHT1, conn)\n",
    "df_mstrcht1\n",
    "# this code gives a code which we can use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_RTRDM1 = \"\"\"\n",
    "SELECT *\n",
    "FROM weather_stations\n",
    "WHERE latitude = '51.962000' AND longitude = '4.447000'\n",
    "\n",
    "\"\"\"\n",
    "df_rtrdm1 = pd.read_sql_query(QUERY_RTRDM1, conn)\n",
    "df_rtrdm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_SCHIPHOL1 = \"\"\"\n",
    "SELECT *\n",
    "FROM weather_stations\n",
    "WHERE latitude = '52.318000' AND longitude = '4.790000'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_sch1 = pd.read_sql_query(QUERY_SCHIPHOL1, conn)\n",
    "df_sch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have all the codes for the correct main points it will be neccesary to also do the same for the smaller points\n",
    "# However these points are in the database called air_quality_stations\n",
    "\n",
    "query_m1 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '50.845941' AND longitude = '5.714745'\n",
    "\n",
    "\"\"\"\n",
    "df_m1 = pd.read_sql_query(query_m1, conn)\n",
    "df_m1\n",
    "# this gives the correct code for this station\n",
    "# the same will be done for all the other smaller stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_m2 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '50.852049' AND longitude = '5.675796'\n",
    "\n",
    "\"\"\"\n",
    "df_m2 = pd.read_sql_query(query_m2, conn)\n",
    "df_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_m3 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '50.859810' AND longitude = '5.713810'\n",
    "\n",
    "\"\"\"\n",
    "df_m3 = pd.read_sql_query(query_m3, conn)\n",
    "df_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now all the stations for main point rotterdam\n",
    "query_r1 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '51.977628' AND longitude = '4.121226'\n",
    "\"\"\"\n",
    "df_r1 = pd.read_sql_query(query_r1, conn)\n",
    "df_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_r1_1 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = ' 51.891147' AND longitude = '4.480690'\n",
    "\"\"\"\n",
    "df_r1_1  = pd.read_sql_query(query_r1_1, conn)\n",
    "df_r1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_r2_3 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '51.938472' AND longitude = '4.430692 '\n",
    "\"\"\"\n",
    "df_r2_3 =pd.read_sql_query(query_r2_2, conn)\n",
    "df_r2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that there is no data available for this air quality station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_r2 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude =  '51.893617'  AND longitude = '4.487528'\n",
    "\"\"\"\n",
    "df_r2 = pd.read_sql_query(query_r2, conn)\n",
    "df_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_r3 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '51.914883' AND longitude = '4.329430' \n",
    "\"\"\"\n",
    "df_r3 = pd.read_sql_query(query_r3, conn)\n",
    "df_r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that there is also no data available for this air quality station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_s1 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '52.327464' AND longitude = '4.715008'\n",
    "\"\"\"\n",
    "df_s1 = pd.read_sql_query(query_s1, conn)\n",
    "df_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_s2 = \"\"\"\n",
    "SELECT *\n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '52.370508' AND longitude =  '4.642319'\n",
    "\"\"\"\n",
    "df_s2 = pd.read_sql_query(query_s2, conn)\n",
    "df_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_s3 = \"\"\"\n",
    "SELECT * \n",
    "FROM air_quality_stations\n",
    "WHERE latitude = '52.334003' AND longitude = '4.774006'\n",
    "\"\"\"\n",
    "df_s3 = pd.read_sql_query(query_s3, conn)\n",
    "df_s3\n",
    "# now that we have all the codes for the stations we can start gathering the data from each of the stations and start plotting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#first redifine the weather factors\n",
    "#this part is just figuring out how to get no_x in the dataset with the wind speed etc like they did in ga1 \n",
    "aq_station_code1 = 'NL50007'\n",
    "weather_station_code1 = '380'\n",
    "QUERY_AQ1 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code1}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ1, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "WEATHER_FACTORS = ['wind_direction', 'wind_speed', 'wind_gust', 'temperature', \n",
    "                  'sunshine_duration', 'global_radiation', 'precipitation', \n",
    "                  'air_pressure', 'visibility', 'cloud_cover', 'humidity', \n",
    "                  'fog', 'rainfall', 'snow', 'thunder', 'ice_formation']\n",
    "\n",
    "QUERY_WEATHER1 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code1} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER1, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "\n",
    "# now join them\n",
    "\n",
    "df_data1 = df_aq.join(df_weather, how='outer')\n",
    "df_data1=df_data1.dropna()\n",
    "df_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aq_station_code2 = 'NL50007'\n",
    "\n",
    "QUERY_AQ2 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code2}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ2, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER2 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code1} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER2, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "# now join them\n",
    "df_data2 = df_aq.join(df_weather, how='outer')\n",
    "df_data2=df_data2.dropna()\n",
    "df_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_station_code3 = 'NL50009'\n",
    "weather_station_code1 = '380'\n",
    "QUERY_AQ3 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code3}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ3, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER1 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code1} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER1, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "# now join them\n",
    "df_data3 = df_aq.join(df_weather, how='outer')\n",
    "df_data3=df_data3.dropna()\n",
    "df_data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the air quality stations around Maastricht did not measure NO_x concentration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_code2 = '344'\n",
    "aq_station_code4 = 'NL01487'\n",
    "QUERY_AQ4 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code4}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ4, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER2 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code2} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER2, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "\n",
    "# Now join them\n",
    "df_r1 = df_aq.join(df_weather, how='outer')\n",
    "#cleaning data\n",
    "df_r1 = df_s1.dropna()\n",
    "#drop outliers\n",
    "Q1 = df_r1.quantile(0.25)\n",
    "Q3 = df_r1.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "threshold = 1.5\n",
    "outliers = ((df_r1 < (Q1 - threshold * IQR)) | (df_r1 > (Q3 + threshold * IQR))).any(axis=1)\n",
    "\n",
    "df_r1_no_outliers = df_r1[~outliers]\n",
    "df_r1_no_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_code2 = '344'\n",
    "aq_station_code5 = 'NL01488'\n",
    "QUERY_AQ5 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code5}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ5, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER2 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code2} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER2, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "# now join them\n",
    "df_r2 = df_aq.join(df_weather, how='outer')\n",
    "#cleaning data\n",
    "df_r2 = df_s1.dropna()\n",
    "#drop outliers\n",
    "Q1 = df_r2.quantile(0.25)\n",
    "Q3 = df_r2.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "threshold = 1.5\n",
    "outliers = ((df_r2 < (Q1 - threshold * IQR)) | (df_r2 > (Q3 + threshold * IQR))).any(axis=1)\n",
    "\n",
    "df_r2_no_outliers = df_r2[~outliers]\n",
    "df_r2_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_code3 = '240'\n",
    "aq_station_code7 = 'NL49564'\n",
    "QUERY_AQ7 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code7}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ7, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER3 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code3} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER3, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "# now join them\n",
    "df_s1 = df_aq.join(df_weather, how='outer')\n",
    "#cleaning data\n",
    "df_s1 = df_s1.dropna()\n",
    "#drop outliers\n",
    "Q1 = df_s1.quantile(0.25)\n",
    "Q3 = df_s1.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "threshold = 1.5\n",
    "outliers = ((df_s1 < (Q1 - threshold * IQR)) | (df_s1 > (Q3 + threshold * IQR))).any(axis=1)\n",
    "\n",
    "df_s1_no_outliers = df_s1[~outliers]\n",
    "df_s1_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aq_station_code8 = 'NL10550'\n",
    "QUERY_AQ8 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code8}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ8, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER3 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code3} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER3, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "# now join them\n",
    "df_s2 = df_aq.join(df_weather, how='outer')\n",
    "# to clean the data\n",
    "df_s2 = df_s2.dropna()\n",
    "Q1 = df_s2.quantile(0.25)\n",
    "Q3 = df_s2.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "threshold = 1.5\n",
    "outliers = ((df_s2 < (Q1 - threshold * IQR)) | (df_s2 > (Q3 + threshold * IQR))).any(axis=1)\n",
    "\n",
    "df_s2_no_outliers = df_s2[~outliers]\n",
    "df_s2_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aq_station_code9 = 'NL49561'\n",
    "QUERY_AQ9 = f\"\"\"\n",
    "    SELECT datetime, {', '.join((compound1, compound2))} \n",
    "    FROM air_quality_data \n",
    "    WHERE station_code='{aq_station_code9}' AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get compound1 and compound2 info of the air quality station\n",
    "df_aq = pd.read_sql_query(QUERY_AQ9, conn, \n",
    "                          index_col='datetime', \n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "QUERY_WEATHER3 = f\"\"\"\n",
    "    SELECT datetime, {', '.join(WEATHER_FACTORS)} \n",
    "    FROM weather_data \n",
    "    WHERE station_code={weather_station_code3} AND datetime>='2015-01-01' AND datetime<='2018-12-31'\n",
    "\"\"\"\n",
    "\n",
    "# Get weather data of the closest weather station\n",
    "df_weather = pd.read_sql_query(QUERY_WEATHER3, conn, \n",
    "                               index_col='datetime', \n",
    "                               parse_dates=['datetime'])\n",
    "# now join them\n",
    "df_s3 = df_aq.join(df_weather, how='outer')\n",
    "# to clean the data\n",
    "df_s3 = df_s3.dropna()\n",
    "Q1 = df_s3.quantile(0.25)\n",
    "Q3 = df_s3.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "threshold = 1.5\n",
    "outliers = ((df_s3 < (Q1 - threshold * IQR)) | (df_s3 > (Q3 + threshold * IQR))).any(axis=1)\n",
    "\n",
    "df_s3_no_outliers = df_s3[~outliers]\n",
    "df_s3_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for basic plotting of the NOx vs wind speed, change y limit for years to get a better view. \n",
    "# can be changed by replacing s3 with another variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_s3_no_outliers['no_x'], label='NOx (Air Quality)')\n",
    "\n",
    "# Plotting 'wind_speed' from weather data\n",
    "plt.plot(df_s3_no_outliers['wind_speed'], label='Wind Speed (Weather)')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('NOx and Wind Speed Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Box-whisker plot for 'no_x' (Air Quality)\n",
    "plt.boxplot(df_s3_no_outliers['no_x'], positions=[1], widths=0.6, labels=['NOx (Air Quality)'])\n",
    "\n",
    "# Box-whisker plot for 'wind_speed' (Weather)\n",
    "plt.boxplot(df_s3_no_outliers['wind_speed'], positions=[2], widths=0.6, labels=['Wind Speed (Weather)'])\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Value')\n",
    "plt.title('NOx and Wind Speed Comparison (Box-Whisker Plot)')\n",
    "plt.ylim(0)  # Ensuring positive values on the y-axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Kernel Density plot for 'no_x' (Air Quality)\n",
    "sns.kdeplot(df_s3_no_outliers['no_x'].dropna(), label='NOx (Air Quality)')\n",
    "\n",
    "# Kernel Density plot for 'wind_speed' (Weather)\n",
    "sns.kdeplot(df_s3_no_outliers['wind_speed'].dropna(), label='Wind Speed (Weather)')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.title('Kernel Density Plot: NOx and Wind Speed Comparison')\n",
    "plt.xlim(0 , 150)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [0, 5, 10, 15, float('inf')]\n",
    "\n",
    "plt.hist(df_s3_no_outliers['wind_speed'], bins=bin_edges, edgecolor='black')\n",
    "\n",
    "plt.title('Histogram wind speed')\n",
    "plt.xlabel('Windspeed')\n",
    "plt.ylabel('distribution')\n",
    "\n",
    "plt.legend(['low (0-10)', 'medium (10-20)', 'high (20-30)', 'extreme (>30)'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot for 'no_x' (Air Quality) against 'wind_speed' (Weather)\n",
    "plt.scatter(df_s3['no_x'], df_s3['wind_speed'], alpha=0.5)\n",
    "plt.xlabel('NOx (Air Quality)')\n",
    "plt.ylabel('Wind Speed (Weather)')\n",
    "plt.title('Scatter Plot: NOx vs Wind Speed')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualisation of the data of station s3 shows that there might be something wrong with the data when it gives a value of 1200 or more micro grams nitrogen oxides per cubic meter air. This gets confirmed when one takes a look at the box-whisker plots where the concentration of nitrogen oxides has a higher amount of outliers compared to the wind speed. This will have a high probability to also show in the data of the other points, since the concentration has a higher variability then the winds speed, mainly because the wind speed is averaged over an period of 10 minutes. In the following plots the data of the other points for schiphol will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for schiphol station 1 shown in a scatter plot\n",
    "\n",
    "plt.scatter(df_s1['no_x'], df_s1['wind_speed'], alpha=0.5)\n",
    "plt.xlabel('NOx (Air Quality)')\n",
    "plt.ylabel('Wind Speed (Weather)')\n",
    "plt.title('Scatter Plot: NOx vs Wind Speed')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Box-whisker plot for 'no_x' (Air Quality)\n",
    "plt.boxplot(df_s1['no_x'].dropna(), positions=[1], widths=0.6, labels=['NOx (Air Quality)'])\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Value')\n",
    "plt.title('NOx and Wind Speed Comparison (Box-Whisker Plot)')\n",
    "plt.ylim(0)  # Ensuring positive values on the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for schiphol station 2 shown in a scatter plot\n",
    "\n",
    "plt.scatter(df_s2['no_x'], df_s2['wind_speed'], alpha=0.5)\n",
    "plt.xlabel('NOx (Air Quality)')\n",
    "plt.ylabel('Wind Speed (Weather)')\n",
    "plt.title('Scatter Plot: NOx vs Wind Speed')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Box-whisker plot for 'no_x' (Air Quality)\n",
    "plt.boxplot(df_s2['no_x'].dropna(), positions=[1], widths=0.6, labels=['NOx (Air Quality)'])\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Value')\n",
    "plt.title('NOx and Wind Speed Comparison (Box-Whisker Plot)')\n",
    "plt.ylim(0)  # Ensuring positive values on the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All of the different stations have a lot of outliers, but station number three has the highest values compared to station number one and two. Station one has on average a lower value compared to the others. In the following graphs the visualization of the data from Maastricht will be shown. However this data will use different stations then we intended to use since the three air quality stations we chose dop not show any readings of a concentration of nitrogen oxides. The coding for these stations will also be shown in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets start with extracting the coordinates of the other air quality stations close to the main weather station in Maastricht\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for Rotterdam station number one\n",
    "plt.scatter(df_r1['no_x'], df_r1['wind_speed'])\n",
    "plt.xlabel('NOx (Air Quality)')\n",
    "plt.ylabel('Wind Speed (Weather)')\n",
    "plt.title('Scatter Plot: NOx vs Wind Speed')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for rotterdam station number two\n",
    "plt.scatter(df_r2['no_x'], df_r2['wind_speed'], alpha=0.5)\n",
    "plt.xlabel('NOx (Air Quality)')\n",
    "plt.ylabel('Wind Speed (Weather)')\n",
    "plt.title('Scatter Plot: NOx vs Wind Speed')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for rotterdam station number three\n",
    "plt.scatter(df_r3['no_x'], df_r3['wind_speed'], alpha=0.5)\n",
    "plt.xlabel('NOx (Air Quality)')\n",
    "plt.ylabel('Wind Speed (Weather)')\n",
    "plt.title('Scatter Plot: NOx vs Wind Speed')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hypothesis testing and interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concentration of NOx decreases with high wind speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "***One-sided or two-sided?***\n",
    "The presented hypothesis is one-sided as it in indicates a clear direction between the two variables. High wind speeds lead to a decrease in the concentration of NOx.\n",
    "\n",
    " \n",
    "***One-sample or two-sample?***\n",
    "The data is two-sample as this investigation aims to find a difference in the concentration of NOx at high wind speeds (a specific group) and low/medium wind speeds.\n",
    "\n",
    "\n",
    "***Equality of means or equality of proportions?***\n",
    "Equality of means is going to be tested as the hypothesis deals with variables that are continuous such as wind speed (measured in metres per second) or concentration of NOx (measured in micrograms per cubic metre).\n",
    "\n",
    "\n",
    "***What is your null hypothesis and what is your alternative hypothesis?***\n",
    "   \n",
    "   *Null hypothesis:*\n",
    "       \n",
    "       The concentration of NOx remains the same for high wind speeds.\n",
    "   *Alternative hypothesis:*\n",
    "       \n",
    "       The concentration of NOx decreases with high wind speeds.\n",
    "\n",
    "\n",
    "***What level of significance are you using?***\n",
    "The level of significance used will be ùõº=0.05, as it is typically used by researchers.\n",
    "\n",
    "\n",
    "***What assumptions do you (need to) make?***\n",
    "The assumption that is going to be made it that the dataset is normally distributed. This can be tested as the dataset is relatively large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_no_x = sm.stats.DescrStatsW(df_s3_no_outliers['no_x'])\n",
    "d_wind_speed = sm.stats.DescrStatsW(df_s3_no_outliers['wind_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompareMeans = sm.stats.CompareMeans(d_no_x, d_wind_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompareMeans.ttest_ind(alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompareMeans.tconfint_diff(alpha=0.05, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "    As seen by the p-value the null hypothesis is rejected, as it gives a value smaller than the level of significance (ùõº=0.05). In addition, the confidence interval does not include 0 which also rejects the null hypothesis. Furthermore, the reason for these results is probably due to the strong correlation between both variables.  \n",
    "\n",
    "4.\n",
    "\n",
    "    After examining the results it can be argued that the alternative hypothesis is true. This is evidenced by the strong correlation between both variables. On the one hand, this could be explained by the fact that high wind speeds might lead to NOx being carried away from the surface and weather stations. However, on the other hand, it can be argued for the null hypothesis by the fact that although there is a trend between both variables this can be due to another factor. For instance, high wind speeds might cause lower temperature which in turn causes lower concentrations of NOx. This way, high wind speed wouldn't be related to the concentration of NOx but still lead to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Polishing and pitching results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is only for generating figures if you need it. You may leave it empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "\n",
    "Please fill in this questionaire to help us improve this course for the next year. Your feedback will be anonymized and will not affect your grade in any way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hours did you spend on these exercises?\n",
    "\n",
    "Assign a number to `feedback_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_1] (0 point)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_1] (0 point)\n",
    "\n",
    "import numbers\n",
    "\n",
    "assert isinstance(feedback_time, numbers.Number), \"Please assign a number to feedback_time\"\n",
    "print(feedback_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How difficult did you find these exercises?\n",
    "\n",
    "Assign an integer to `feedback_difficulty`, on a scale 0 - 10, with 0 being very easy, 5 being just right, and 10 being very difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_2] (0 point)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_2] (0 point)\n",
    "\n",
    "import numbers\n",
    "\n",
    "assert isinstance(feedback_difficulty, numbers.Number), \"Please assign a number to feedback_difficulty\"\n",
    "print(feedback_difficulty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) What did you like?\n",
    "\n",
    "Assign a string to `feedback_like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_3] (0 point)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_3] (0 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) What can be improved?\n",
    "\n",
    "Assign a string to `feedback_improve`. Please be specific, so that we can act on your feedback. For example, mention the specific exercises and what was unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_4] (0 point)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_4] (0 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## How to Submit Your Work\n",
    "\n",
    "1. **Before submitting**, you must run your notebook by doing **Kernel > Restart & Run All**.  \n",
    "   Make sure that your notebook runs without errors **in linear order**.\n",
    "1. Remember to rename the notebook as explained at the beginning of this notebook.\n",
    "1. Submit the executed notebook with your work\n",
    "   for the appropriate assignment in **Canvas**.\n",
    "1. In the **Momotor** tab in Canvas,\n",
    "  you can select that assignment again to find some feedback on your submitted work.\n",
    "  If there are any problems reported by _Momotor_,\n",
    "  then you need to fix those,\n",
    "  and **resubmit the fixed notebook**.\n",
    "\n",
    "In case of a high workload on our server\n",
    "(because many students submit close to the deadline),\n",
    "it may take longer to receive the feedback.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all defined names\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# (End of Notebook) <span class=\"tocSkip\"></span>\n",
    "\n",
    "&copy; 2017-2023 - **TU/e** - Eindhoven University of Technology"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "60e5673dee0b20898bfa4f3c497959fb0c8d0d39a7f6ea9d7f166a7012267d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
